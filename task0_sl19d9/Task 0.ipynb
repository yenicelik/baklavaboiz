{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "We use the pandas library for this. The data is split into 3 files:\n",
    "- sample.csv :: Some stuff we can look at to know how the bigger and slower-to-load datafiles look like\n",
    "- test.csv :: Validation data, which we use to 'grade' our model by\n",
    "- train.csv :: Data we use to train our model with (to find the 'optimal' parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sample = pd.read_csv('sample.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to know how the data looks like, let us print the first 10 training-samples for each data-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "      Id       y\n",
      "0  10000  2000.0\n",
      "1  10001  2001.0\n",
      "2  10002  2002.0\n",
      "Test\n",
      "      Id           x1           x2          x3          x4          x5  \\\n",
      "0  10000  -483.797492  1288.057065 -129.878712 -198.078388 -334.487592   \n",
      "1  10001  -316.407305    30.830556 -313.356726 -173.259184 -327.368719   \n",
      "2  10002 -2448.558997  -561.988408  355.098820  634.378170 -392.450091   \n",
      "\n",
      "           x6           x7          x8           x9          x10  \n",
      "0 -391.443186  -612.406176 -676.523964  1327.229655  -448.695446  \n",
      "1  944.368248  1122.017380  112.338731  1372.340221  2062.561842  \n",
      "2 -813.156399  -232.873263  246.801210  -562.413197  -841.602015  \n",
      "Train\n",
      "   Id           y           x1           x2          x3           x4  \\\n",
      "0   0  738.023171  1764.052346   400.157208  978.737984  2240.893199   \n",
      "1   1  400.646015   144.043571  1454.273507  761.037725   121.675016   \n",
      "2   2  189.900156 -2552.989816   653.618595  864.436199  -742.165020   \n",
      "\n",
      "            x5           x6           x7          x8           x9          x10  \n",
      "0  1867.557990  -977.277880   950.088418 -151.357208  -103.218852   410.598502  \n",
      "1   443.863233   333.674327  1494.079073 -205.158264   313.067702  -854.095739  \n",
      "2  2269.754624 -1454.365675    45.758517 -187.183850  1532.779214  1469.358770  \n"
     ]
    }
   ],
   "source": [
    "cases = 3\n",
    "print \"Sample\"\n",
    "print data_sample.head(cases)\n",
    "print \"Test\"\n",
    "print data_test.head(cases)\n",
    "print \"Train\"\n",
    "print data_train.head(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 'headers' (Thing like 'Id', 'y', 'x1', 'x2', etc.). For pure data processing we need to get rid of this (because these are not numebrs), and just retrieve the numerical values within the matrices. CV stands for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = (10000 / 5) * 4 #first few examples\n",
    "cv_size = (10000 / 5) * 1 #last few examples #lazy evaluation of size of the training size\n",
    "\n",
    "y_sample = data_sample.values\n",
    "X_test = data_test.values[:,1:]\n",
    "X_train = data_train.values[:train_size,2:]\n",
    "y_train = data_train.values[:train_size,1]\n",
    "X_cv = data_train.values[train_size:,2:]\n",
    "y_cv = data_train.values[train_size:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure the import was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[ 1764.05234597   400.15720837   978.73798411 ...,  -151.3572083\n",
      "   -103.21885179   410.59850194]\n",
      " [  144.04357116  1454.27350696   761.03772515 ...,  -205.15826377\n",
      "    313.06770165  -854.0957393 ]\n",
      " [-2552.98981583   653.61859544   864.43619886 ...,  -187.18385003\n",
      "   1532.77921436  1469.3587699 ]\n",
      " ..., \n",
      " [   27.45669686   -19.03954586   297.35599943 ...,   818.21746148\n",
      "   1297.81973773   616.74435846]\n",
      " [  279.8876014  -1109.80653015  -428.07813862 ...,   855.35708635\n",
      "   -535.80122196  -142.07524446]\n",
      " [  338.39140718 -1360.41534307  1059.45392275 ..., -1048.73452712\n",
      "    374.75842004  -987.31143098]]\n",
      "y_train\n",
      "[ 738.02317073  400.64601516  189.9001559  ...,  315.45915294 -104.07126633\n",
      "   97.97483287]\n"
     ]
    }
   ],
   "source": [
    "print \"X_train\"\n",
    "print X_train\n",
    "print \"y_train\"\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions and Applications\n",
    "Here we define the functions we will use to predict the weights (normalEq, or maybe even stochastic gradient descent), and also the given error function (rms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rms(pred, y):\n",
    "    out = (1./pred.shape[0]) * np.sum(np.square(pred - y), axis=0)\n",
    "    return out**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalEq(X, y):\n",
    "    print \"X:\"\n",
    "    print X.shape\n",
    "    print \"y:\"\n",
    "    print y.shape\n",
    "    lhs = np.dot(X.transpose(), X)\n",
    "    lhsinv = np.linalg.inv(lhs)\n",
    "    rhs = np.dot(X.transpose(), y)\n",
    "    return np.dot( lhsinv, rhs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the normalEq, which gives us the weights to predict the y-data GIVEN the X-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "(8000, 10)\n",
      "y:\n",
      "(8000,)\n",
      "\n",
      "Weights:\n",
      "[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n"
     ]
    }
   ],
   "source": [
    "weight = normalEq(X_train, y_train)\n",
    "print\n",
    "print \"Weights:\"\n",
    "print weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test what are error residual is (how close our prediction is to the real prediction). This is expressed as a relative error (not absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error, expressed as |y_actual - (X_cv * weights)|/|(X_cv * weights)|:\n",
      "1.69316590935e-16\n"
     ]
    }
   ],
   "source": [
    "u = -np.dot(X_cv, weight)\n",
    "u += y_cv\n",
    "sumu = np.abs(np.sum(u))\n",
    "v = np.abs(np.sum(np.dot(X_cv, weight)))\n",
    "\n",
    "print \"Relative error, expressed as |y_actual - (X_cv * weights)|/|(X_cv * weights)|:\"\n",
    "print sumu/v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bring the function into the submission format: Post-Processing\n",
    "We have trained the weights using the training data (X_train). Remember that the sample submission data looks like the following. That means we need to predict for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "      Id       y\n",
      "0  10000  2000.0\n",
      "1  10001  2001.0\n",
      "2  10002  2002.0\n",
      "         Id       y\n",
      "1997  11997  3997.0\n",
      "1998  11998  3998.0\n",
      "1999  11999  3999.0\n",
      "Test\n",
      "      Id           x1           x2          x3          x4          x5  \\\n",
      "0  10000  -483.797492  1288.057065 -129.878712 -198.078388 -334.487592   \n",
      "1  10001  -316.407305    30.830556 -313.356726 -173.259184 -327.368719   \n",
      "2  10002 -2448.558997  -561.988408  355.098820  634.378170 -392.450091   \n",
      "\n",
      "           x6           x7          x8           x9          x10  \n",
      "0 -391.443186  -612.406176 -676.523964  1327.229655  -448.695446  \n",
      "1  944.368248  1122.017380  112.338731  1372.340221  2062.561842  \n",
      "2 -813.156399  -232.873263  246.801210  -562.413197  -841.602015  \n",
      "         Id          x1           x2           x3          x4           x5  \\\n",
      "1997  11997  199.864648   261.345779  -127.986805 -298.503216  -364.240174   \n",
      "1998  11998 -151.673157 -1425.199620  1070.922114  938.800763  1373.176372   \n",
      "1999  11999  -97.089983   780.444250   221.081520   72.748763 -1484.861623   \n",
      "\n",
      "               x6           x7           x8           x9          x10  \n",
      "1997 -1370.134911   769.662730  -517.182892    79.694141  1016.126607  \n",
      "1998  -583.905998  -292.269529 -1206.766021 -1047.464871     7.588102  \n",
      "1999   462.159812  1549.025158  2531.705492   -35.722034   173.200191  \n"
     ]
    }
   ],
   "source": [
    "print \"Sample\"\n",
    "print data_sample.head(cases)\n",
    "print data_sample.tail(cases)\n",
    "print \"Test\"\n",
    "print data_test.head(cases)\n",
    "print data_test.tail(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, calculate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n",
      "(10,)\n",
      "(2000,)\n",
      "[ -66.00242349  451.4065044  -461.67641706 ...,  -35.13540942 -131.67918453\n",
      "  417.26915462]\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape\n",
    "print weight.shape\n",
    "y_pred_test = np.dot(X_test, weight)\n",
    "print y_pred_test.shape\n",
    "print y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission format includes the ID's taken from the X-training data. Each invidual record has a predicted 'y' record aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "[[ 10000.            -66.00242349]\n",
      " [ 10001.            451.4065044 ]\n",
      " [ 10002.           -461.67641706]\n",
      " ..., \n",
      " [ 11997.            -35.13540942]\n",
      " [ 11998.           -131.67918453]\n",
      " [ 11999.            417.26915462]]\n"
     ]
    }
   ],
   "source": [
    "sub_data = np.column_stack((data_test.values[:,0], y_pred_test))\n",
    "print sub_data.shape\n",
    "print sub_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This look alright... Let's wrap it in a pandas-dataframe (that's what the datastructures including the headers with 'ID' and 'y' are called)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id           y\n",
      "0     10000  -66.002423\n",
      "1     10001  451.406504\n",
      "2     10002 -461.676417\n",
      "3     10003   40.501209\n",
      "4     10004 -126.744722\n",
      "5     10005 -342.534552\n",
      "6     10006 -396.555542\n",
      "7     10007  335.541279\n",
      "8     10008  -99.512421\n",
      "9     10009  304.812540\n",
      "10    10010   68.894530\n",
      "11    10011  412.369195\n",
      "12    10012   54.942371\n",
      "13    10013  -17.005551\n",
      "14    10014 -597.849958\n",
      "15    10015  443.502289\n",
      "16    10016  144.774487\n",
      "17    10017  -57.411164\n",
      "18    10018  134.387828\n",
      "19    10019 -108.983776\n",
      "20    10020  153.824828\n",
      "21    10021  611.735984\n",
      "22    10022  588.389650\n",
      "23    10023 -131.016800\n",
      "24    10024  -61.135621\n",
      "25    10025 -374.248495\n",
      "26    10026   74.157993\n",
      "27    10027  137.438379\n",
      "28    10028  420.086612\n",
      "29    10029  196.765626\n",
      "...     ...         ...\n",
      "1970  11970 -228.376122\n",
      "1971  11971  198.061607\n",
      "1972  11972 -713.006477\n",
      "1973  11973  -89.681865\n",
      "1974  11974 -480.004570\n",
      "1975  11975 -271.733396\n",
      "1976  11976  565.323640\n",
      "1977  11977   96.111483\n",
      "1978  11978  178.613359\n",
      "1979  11979  -61.174332\n",
      "1980  11980 -368.691687\n",
      "1981  11981    4.847747\n",
      "1982  11982  414.413821\n",
      "1983  11983 -760.318317\n",
      "1984  11984   84.912715\n",
      "1985  11985 -251.847326\n",
      "1986  11986  280.707585\n",
      "1987  11987 -391.250278\n",
      "1988  11988  608.499117\n",
      "1989  11989  -27.808461\n",
      "1990  11990 -123.414119\n",
      "1991  11991 -130.829244\n",
      "1992  11992   18.553069\n",
      "1993  11993 -433.165376\n",
      "1994  11994 -303.709126\n",
      "1995  11995  464.715255\n",
      "1996  11996  496.485334\n",
      "1997  11997  -35.135409\n",
      "1998  11998 -131.679185\n",
      "1999  11999  417.269155\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(sub_data, columns = [\"Id\", \"y\"])\n",
    "submission.Id = submission.Id.astype(int)\n",
    "print submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** I'M NOT SURE IF IT HAS TO BE 1-point PRECISION (last record to be 417.3, instead of 417.269155). ALSO, THE ID COLUMN STILL CONTAINS DOTS ALTHOUGH THE SAMPLE SUBMISSION FORM DOES NOT EXACTLY MATCH THIS ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not let's export the submission file as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = submission.to_csv('final_submission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
