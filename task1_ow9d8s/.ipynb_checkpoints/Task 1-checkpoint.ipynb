{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    import pip\n",
    "    pip.main(['install', \"--upgrade\", \"pip\"])\n",
    "    pip.main(['install', \"numpy\"])\n",
    "    pip.main(['install', \"matplotlib\"])\n",
    "    pip.main(['install', \"ipython\"])\n",
    "    pip.main(['install', \"jupyter\"])\n",
    "    pip.main(['install', \"pandas\"])\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "We use the pandas library for this. The data is split into 3 files:\n",
    "- sample.csv :: Some stuff we can look at to know how the bigger and slower-to-load datafiles look like\n",
    "- test.csv :: Validation data, which we use to 'grade' our model by\n",
    "- train.csv :: Data we use to train our model with (to find the 'optimal' parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "    Id         y\n",
      "0  900  6.055126\n",
      "Test\n",
      "    Id        x1        x2       x3       x4        x5        x6        x7  \\\n",
      "0  900  0.658913  1.489215  1.65309  2.68705  0.613798  1.599903  1.345002   \n",
      "\n",
      "         x8       x9       x10       x11       x12       x13       x14  \\\n",
      "0  1.617774 -0.48859  2.893903  3.800831 -0.018902  0.857224  0.881235   \n",
      "\n",
      "       x15  \n",
      "0  0.57476  \n",
      "Train\n",
      "   Id           y        x1        x2        x3        x4       x5        x6  \\\n",
      "0   0  116.376061  1.276266 -0.854628  1.623901  2.145311  2.03719  2.886639   \n",
      "\n",
      "         x7        x8        x9       x10       x11      x12       x13  \\\n",
      "0  0.888302  0.637899  1.148675  0.562217  3.171257  2.15231 -0.818812   \n",
      "\n",
      "        x14      x15  \n",
      "0  0.861951  1.53984  \n"
     ]
    }
   ],
   "source": [
    "data_sample = pd.read_csv('sample.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_train = pd.read_csv('train.csv')\n",
    "\n",
    "cases = 1\n",
    "if True:\n",
    "    print(\"Sample\")\n",
    "    print(data_sample.head(cases))\n",
    "    print(\"Test\")\n",
    "    print(data_test.head(cases))\n",
    "    print(\"Train\")\n",
    "    print(data_train.head(cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 'headers' (Thing like 'Id', 'y', 'x1', 'x2', etc.). For pure data processing we need to get rid of this (because these are not numebrs), and just retrieve the numerical values within the matrices. CV stands for cross-validation. Printing the shapes is just to make sure the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "(900, 17)\n",
      "y_sample\n",
      "(2000, 2)\n",
      "X_finaltest\n",
      "(2000, 15)\n",
      "And has types\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "X_data = data_train.values\n",
    "y_sample = data_sample.values\n",
    "X_test = data_test.values[:,1:]\n",
    "\n",
    "if True:\n",
    "    print(\"X_train\")\n",
    "    print(X_data.shape)\n",
    "    print(\"y_sample\")\n",
    "    print(y_sample.shape)\n",
    "    print(\"X_finaltest\")\n",
    "    print(X_test.shape)\n",
    "\n",
    "    print(\"And has types\")\n",
    "    print(type(X_test[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions and Applications\n",
    "Here we define the functions we will use to predict the weights (normalEq, or maybe even stochastic gradient descent), and also the given error function (rms). Trying out different algorithms and testing them through cross-validation. Look at the external files for the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equations \n",
    "#### with regulaizer parameters = lam\n",
    "We test a total of 10000 different values for lambda in between 1e-20 and 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total samples: ', 900)\n",
      "(180, 15)\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "from normalEq import *\n",
    "\n",
    "k = 5 #number of folds for cross validation\n",
    "\n",
    "if X_data.shape[0] % k != 0:\n",
    "    print(\"Number of samples not divisible by k!\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "print(\"Total samples: \", X_data.shape[0])\n",
    "\n",
    "total_error = 0.0\n",
    "\n",
    "X = np.split(X_data[:,2:], k, axis=0)\n",
    "y = np.split(X_data[:,1], k, axis=0)\n",
    "\n",
    "print(X[0].shape)\n",
    "print(y[0].shape)\n",
    "\n",
    "loss_dict = []\n",
    "lam_dict = []\n",
    "\n",
    "lam_range = np.logspace(-16, 10, num=10000)#[1e-8, 1e-3, 1e2]\n",
    "\n",
    "#Apply cross validation\n",
    "for lam in lam_range:\n",
    "    loss = 0\n",
    "    for i in range(k):\n",
    "        X_train, y_train, X_cv, y_cv = get_train_cross_dataset(X, y, i)\n",
    "\n",
    "        #apply to training function, then measure the error\n",
    "        weights = reg_normal_eq(X_train, y_train, lam)\n",
    "        \n",
    "        ##Measure loss\n",
    "        predictions = np.dot(X_cv, weights)\n",
    "        loss = rms(predictions, y_cv)    \n",
    "    \n",
    "    total_error += loss    \n",
    "    total_error /= k\n",
    "    \n",
    "    lam_dict.append(lam)\n",
    "    loss_dict.append(total_error)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAADCCAYAAAB6xtfuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116cea850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Absolute training loss')\n",
    "plt.xlabel('Lambda')\n",
    "plt.semilogx(lam_dict, loss_dict, 'o')\n",
    "#plt.plot(lam_dict, 'o', label='baseline')\n",
    "#plt.plot(loss_dict, 'o', label='batchnorm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The minimal error is given when lambda equals: ', 9.9999999999999995e-21)\n"
     ]
    }
   ],
   "source": [
    "print(\"The minimal error is given when lambda equals: \", lam_dict[loss_dict.index(min(loss_dict))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's check if gradient descent actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.38397097621479, 57.287924667801818, 54.013897309227175, 51.432605027957152, 49.309160776628048, 47.592970340839351, 46.164807261349935, 44.99507163769934, 44.016928416986055, 43.208691895901453, 42.530546749691659, 41.966025866622672, 41.490581600770312, 41.09198358072527, 40.754760666955193, 40.470059212619709, 40.227954797176743, 40.02214936212799, 39.846170327294416, 39.695578417975454]\n",
      "[65.20931015096248, 58.448775396321949, 57.522348181365082, 53.879159172484435, 52.914999430271486, 50.846784190180514, 50.037459968785384, 48.814688798321875, 48.203700311693282, 47.459289067203855, 47.024196978799473, 46.561784054277325, 46.26248794698855, 45.971502340368943, 45.770170499300278, 45.585782028887351, 45.452577808864, 45.335571886847447, 45.248757530713505, 45.174839187693891]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "mu = 0.1\n",
    "\n",
    "w = np.random.normal(0.0, 1.0, size=(X_train.shape[1])) #must be adaptable to X\n",
    "\n",
    "train_loss_list, cv_loss_list, w = run_sgd(X[0], y[0], X[1], y[1], w, mu, lr, rms, MAX_STEPS=20)\n",
    "\n",
    "print(train_loss_list)\n",
    "print(cv_loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems fine, as all loss values decrese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total samples: ', 900)\n",
      "(180, 15)\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "from sgd import *\n",
    "\n",
    "k = 5 #number of folds for cross validation\n",
    "\n",
    "if X_data.shape[0] % k != 0:\n",
    "    print(\"Number of samples not divisible by k!\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "print(\"Total samples: \", X_data.shape[0])\n",
    "\n",
    "total_error = 0.0\n",
    "\n",
    "X = np.split(X_data[:,2:], k, axis=0)\n",
    "y = np.split(X_data[:,1], k, axis=0)\n",
    "\n",
    "print(X[0].shape)\n",
    "print(y[0].shape)\n",
    "\n",
    "loss_dict = []\n",
    "lr_dict = []\n",
    "mu_dict = []\n",
    "\n",
    "lr_range = np.logspace(-3, 1, num=500)\n",
    "mu_range = np.logspace(-3, 1, num=500)\n",
    "\n",
    "\n",
    "#Initialize everything\n",
    "w = np.random.normal(0.0, 1.0, size=(X_train.shape[1])) #must be adaptable to X\n",
    "\n",
    "#Apply cross validation\n",
    "for lr in lr_range:\n",
    "    for mu in mu_range:\n",
    "        \n",
    "        total_error = 0\n",
    "         \n",
    "        for i in range(k):\n",
    "            X_train, y_train, X_cv, y_cv = get_train_cross_dataset(X, y, i)\n",
    "            \n",
    "            train_loss_dict, cv_loss_dict, w = run_sgd(\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train,\n",
    "                                                        X_cv=X_cv, \n",
    "                                                        y_cv=y_cv,\n",
    "                                                        w=w, \n",
    "                                                        mu=mu, \n",
    "                                                        lr=lr, \n",
    "                                                        fn_loss=rms, \n",
    "                                                        MAX_STEPS=1000\n",
    "                                                        )    \n",
    "            ##Measure loss\n",
    "            loss = cv_loss_dict[-1] #last one describes the achieved loss\n",
    "            total_error += loss\n",
    "            \n",
    "            \n",
    "        total_error /= k\n",
    "        \n",
    "        lr_dict.append(lr)\n",
    "        mu_dict.append(mu)\n",
    "        loss_dict.append(total_error)  \n",
    "\n",
    "#print(lr_dict)\n",
    "#print(mu_dict)\n",
    "#print(loss_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAC9CAYAAACajoh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOmBSJUmS1AGTKkmSpA6YVEmSJHXg/wPakC8YFFNcBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1159110d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Absolute training loss')\n",
    "plt.xlabel('Combinations')\n",
    "plt.plot(loss_dict, 'o')\n",
    "#plt.plot(lam_dict, 'o', label='baseline')\n",
    "#plt.plot(loss_dict, 'o', label='batchnorm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bring the function into the submission format: Post-Processing\n",
    "We have trained the weights using the training data (X_train). Remember that the sample submission data looks like the following. That means we need to predict for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"Sample\")\n",
    "    print(data_sample.head(cases))\n",
    "    print(data_sample.tail(cases))\n",
    "    print(\"Test\")\n",
    "    print(data_test.head(cases))\n",
    "    print(data_test.tail(cases))\n",
    "    print(X_finaltest.shape)\n",
    "    print(weights.shape)\n",
    "    print(y_pred_test.shape)\n",
    "    print(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, calculate the predictions. Don't forget to stack a bias column. The submission format includes the ID's taken from the X-training data. Each invidual record has a predicted 'y' record aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2000,11) and (10,) not aligned: 11 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a1d313d33a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finaltest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finaltest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2000,11) and (10,) not aligned: 11 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "y_pred_test = np.dot(np.column_stack((X_finaltest, np.ones(X_finaltest.shape[0]))), weights)\n",
    "sub_data = np.column_stack((data_test.values[:,0], y_pred_test))\n",
    "print(sub_data.shape)\n",
    "print(sub_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This look alright... Let's wrap it in a pandas-dataframe (that's what the datastructures including the headers with 'ID' and 'y' are called)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id                         y\n",
      "0     10000  -66.00242349023130827845\n",
      "1     10001  451.40650440115518904349\n",
      "2     10002 -461.67641706029962733737\n",
      "3     10003   40.50120875372320483621\n",
      "4     10004 -126.74472245403632086891\n",
      "5     10005 -342.53455181925158967715\n",
      "6     10006 -396.55554211359054761488\n",
      "7     10007  335.54127907908764427702\n",
      "8     10008  -99.51242087062264829456\n",
      "9     10009  304.81253980627650435054\n",
      "10    10010   68.89453048978556637394\n",
      "11    10011  412.36919545590848201755\n",
      "12    10012   54.94237102476856193789\n",
      "13    10013  -17.00555075478039768200\n",
      "14    10014 -597.84995757226056412037\n",
      "15    10015  443.50228878641490837254\n",
      "16    10016  144.77448697804288713087\n",
      "17    10017  -57.41116367253620467181\n",
      "18    10018  134.38782757746042761937\n",
      "19    10019 -108.98377598910846586477\n",
      "20    10020  153.82482842506630049684\n",
      "21    10021  611.73598360220182712510\n",
      "22    10022  588.38965033842225693661\n",
      "23    10023 -131.01679995802052758336\n",
      "24    10024  -61.13562114123003965460\n",
      "25    10025 -374.24849531697236670880\n",
      "26    10026   74.15799307965411912846\n",
      "27    10027  137.43837873610536348679\n",
      "28    10028  420.08661179679069164195\n",
      "29    10029  196.76562571344160801345\n",
      "...     ...                       ...\n",
      "1970  11970 -228.37612245128613608358\n",
      "1971  11971  198.06160680946024399418\n",
      "1972  11972 -713.00647693430278195592\n",
      "1973  11973  -89.68186474183370648916\n",
      "1974  11974 -480.00457016777994567747\n",
      "1975  11975 -271.73339592270008324704\n",
      "1976  11976  565.32363993667070189986\n",
      "1977  11977   96.11148263232833244274\n",
      "1978  11978  178.61335856961233048423\n",
      "1979  11979  -61.17433245470591174353\n",
      "1980  11980 -368.69168724005919557385\n",
      "1981  11981    4.84774657817800846971\n",
      "1982  11982  414.41382134440124218600\n",
      "1983  11983 -760.31831679305116722389\n",
      "1984  11984   84.91271532686188550088\n",
      "1985  11985 -251.84732552029109342584\n",
      "1986  11986  280.70758458951968350448\n",
      "1987  11987 -391.25027825107639500857\n",
      "1988  11988  608.49911717037446123868\n",
      "1989  11989  -27.80846060721255952330\n",
      "1990  11990 -123.41411926925461273186\n",
      "1991  11991 -130.82924419408300309442\n",
      "1992  11992   18.55306889260260305718\n",
      "1993  11993 -433.16537587721256841178\n",
      "1994  11994 -303.70912611646485856909\n",
      "1995  11995  464.71525498507958218397\n",
      "1996  11996  496.48533446727839191226\n",
      "1997  11997  -35.13540941579512377757\n",
      "1998  11998 -131.67918453438889514473\n",
      "1999  11999  417.26915462133581513626\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_info_rows', 11)\n",
    "pd.set_option('precision',20)\n",
    "submission = pd.DataFrame(sub_data, columns = [\"Id\", \"y\"])\n",
    "submission.Id = submission.Id.astype(int)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** I'M NOT SURE IF IT HAS TO BE 1-point PRECISION (last record to be 417.3, instead of 417.269155). ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not let's export the submission file as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = submission.to_csv('final_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
